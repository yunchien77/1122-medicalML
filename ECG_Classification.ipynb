{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDIlZS8SCFOA"
      },
      "source": [
        "This tutorial is modified from https://www.kaggle.com/rkuo2000/ecg-classification/comments#778183\n",
        "\n",
        "Model design based on ECG Heartbeat Classification: [A Deep Transferable Representation](https://arxiv.org/pdf/1805.00794.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZojIpYf7bARy",
        "cellView": "form"
      },
      "source": [
        "#@title Show GPU infomation\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEWw3qqPvS7T"
      },
      "source": [
        "#@title Download data and unzip the file from google drive share-link\n",
        "#@markdown Data sourceï¼šhttps://www.kaggle.com/shayanfazeli/heartbeat\n",
        "!gdown --id 1O0_YAHtdEc2uO9R4rX5hYlN7DIY6y3qX\n",
        "!unzip -n -q 'heartbeat.zip'\n",
        "print(\"... done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q-qhG4NXPMB"
      },
      "source": [
        "# -- Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-aQssIjYM4l"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.signal import resample\n",
        "from scipy import interp\n",
        "from itertools import cycle, product\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Softmax, Add, Flatten, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXxAFfj2Yi0n"
      },
      "source": [
        "# 1 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iJhZG_ZYigZ"
      },
      "source": [
        "#@title load dataset\n",
        "df = pd.read_csv(\"mitbih_train.csv\", header=None)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqNXtYcOZJV0"
      },
      "source": [
        "# show one data    # colume 187 is target label\n",
        "idx = 1000\n",
        "plt.plot(df.iloc[idx,:187])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDjKu5mQaO0J"
      },
      "source": [
        "#@title define dataset X and y\n",
        "M = df.values  # numpy array M\n",
        "X = M[:, :-1]  # column 0-186\n",
        "y = M[:, -1].astype(int)  # # column 187\n",
        "print(\"dataset X shape =\", X.shape)\n",
        "print(\"dataset y shape =\", y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBQG-Ppjcju6"
      },
      "source": [
        "## visualize dataset X\n",
        "C0_idx = np.argwhere(y==0).flatten()\n",
        "C1_idx = np.argwhere(y==1).flatten()\n",
        "C2_idx = np.argwhere(y==2).flatten()\n",
        "C3_idx = np.argwhere(y==3).flatten()\n",
        "C4_idx = np.argwhere(y==4).flatten()\n",
        "\n",
        "t = np.arange(0, 187) * (1/125) * 1000  # time-line with Sampling Frequency: 125Hz\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(t, X[C0_idx, :][0], label=\"C0: N\")\n",
        "plt.plot(t, X[C1_idx, :][0], label=\"C1: S\")\n",
        "plt.plot(t, X[C2_idx, :][0], label=\"C2: V\")\n",
        "plt.plot(t, X[C3_idx, :][0], label=\"C3: F\")\n",
        "plt.plot(t, X[C4_idx, :][0], label=\"C4: Q\")\n",
        "plt.legend()\n",
        "plt.title(\"1-beat ECG for every category\", fontsize=20)\n",
        "plt.ylabel(\"Amplitude\", fontsize=15)\n",
        "plt.xlabel(\"Time (ms)\", fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urJNatVYZgL1"
      },
      "source": [
        "# show number of each class\n",
        "class_num = [ C0_idx.shape[0], C1_idx.shape[0], C2_idx.shape[0], C3_idx.shape[0], C4_idx.shape[0]]\n",
        "print(\"number of each class: C0, C1, C2, C3, C4 =\", class_num)\n",
        "\n",
        "# plot the circle of class counts\n",
        "plt.figure(figsize=(6,6))\n",
        "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
        "plt.pie(class_num, labels=['C0','C1','C2','C3','C4'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOoimB_ugRsJ"
      },
      "source": [
        "## split dataset to training_set and valid_set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa78o6gsivDZ"
      },
      "source": [
        "# train_test_split (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "val_set_ratio = 0.2\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_set_ratio, random_state=42)\n",
        "\n",
        "# set channel last\n",
        "X_train = X_train[:,:,np.newaxis]  # as shape (number_of_data, X_lengh, channel)\n",
        "X_val = X_val[:,:,np.newaxis]  # as shape (number_of_data, X_lengh, channel)\n",
        "\n",
        "print(\"class count train : (C0:\", X_train[np.argwhere(y_train==0)].shape[0], \", C1:\", X_train[np.argwhere(y_train==1)].shape[0], \", C2:\", X_train[np.argwhere(y_train==2)].shape[0], \", C3:\", X_train[np.argwhere(y_train==3)].shape[0], \", C4:\", X_train[np.argwhere(y_train==4)].shape[0], \")\")\n",
        "print(\"class count val   : (C0:\", X_val[np.argwhere(y_val==0)].shape[0], \", C1:\", X_val[np.argwhere(y_val==1)].shape[0], \", C2:\", X_val[np.argwhere(y_val==2)].shape[0], \", C3:\", X_val[np.argwhere(y_val==3)].shape[0], \", C4:\", X_val[np.argwhere(y_val==4)].shape[0], \")\")\n",
        "print(\"X_train shape =\", X_train.shape)\n",
        "print(\"y_train shape =\", y_train.shape)\n",
        "print(\"X_val shape =\", X_val.shape)\n",
        "print(\"y_val shape =\", y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiplTq62fgNS"
      },
      "source": [
        "## balance dataset via augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC673fX3c1gZ"
      },
      "source": [
        "def stretch(x):\n",
        "    l = int(187 * (1 + (random.random()-0.5)/3))\n",
        "    y = resample(x, l)\n",
        "    if l < 187:\n",
        "        y_ = np.zeros(shape=(187, ))\n",
        "        y_[:l] = y\n",
        "    else:\n",
        "        y_ = y[:187]\n",
        "    return y_\n",
        "\n",
        "def amplify(x):\n",
        "    alpha = (random.random()-0.5)\n",
        "    factor = -alpha*x + (1+alpha)\n",
        "    return x*factor\n",
        "\n",
        "def augment(x):\n",
        "    # 4 times augmentation\n",
        "    result = np.zeros(shape= (4, 187))\n",
        "    for i in range(3):\n",
        "        if random.random() < 0.33:\n",
        "            new_x = stretch(x)\n",
        "        elif random.random() < 0.66:\n",
        "            new_x = amplify(x)\n",
        "        else:\n",
        "            new_x = stretch(x)\n",
        "            new_x = amplify(new_x)\n",
        "        result[i, :] = new_x\n",
        "    return result\n",
        "\n",
        "plt.title(\"Demo of one augmentation\")\n",
        "plt.plot(X[0, :], 'b', label=\"origin\")\n",
        "plt.plot(amplify(X[0, :]), '--', label=\"Aug amplify\")\n",
        "plt.plot(stretch(X[0, :]), '--', label=\"Aug stretch\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiwyOrVrVAtw"
      },
      "source": [
        "print(\"before augmentation:\")\n",
        "print(\"class count train : (C0:\", X_train[np.argwhere(y_train==0)].shape[0], \", C1:\", X_train[np.argwhere(y_train==1)].shape[0], \", C2:\", X_train[np.argwhere(y_train==2)].shape[0], \", C3:\", X_train[np.argwhere(y_train==3)].shape[0], \", C4:\", X_train[np.argwhere(y_train==4)].shape[0], \")\")\n",
        "print(\"class count val   : (C0:\", X_val[np.argwhere(y_val==0)].shape[0], \", C1:\", X_val[np.argwhere(y_val==1)].shape[0], \", C2:\", X_val[np.argwhere(y_val==2)].shape[0], \", C3:\", X_val[np.argwhere(y_val==3)].shape[0], \", C4:\", X_val[np.argwhere(y_val==4)].shape[0], \")\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYko2cw9ehVB"
      },
      "source": [
        "#@title apply augmentation\n",
        "\n",
        "# augment C3 5 times\n",
        "def augment_C3(X, y):\n",
        "    C3_idx = np.argwhere(y==3).flatten()\n",
        "    result = np.apply_along_axis(augment, axis=1, arr=X[C3_idx]).reshape(-1, 187, 1)\n",
        "    classe = np.ones(shape=(result.shape[0],), dtype=int)*3\n",
        "    # append aug_data to training dataset\n",
        "    X = np.vstack([X, result])\n",
        "    y = np.hstack([y, classe])\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = augment_C3(X_train, y_train)\n",
        "X_val, y_val = augment_C3(X_val, y_val)\n",
        "\n",
        "print(\"after augmentation:\")\n",
        "print(\"class count train : (C0:\", X_train[np.argwhere(y_train==0)].shape[0], \", C1:\", X_train[np.argwhere(y_train==1)].shape[0], \", C2:\", X_train[np.argwhere(y_train==2)].shape[0], \", C3:\", X_train[np.argwhere(y_train==3)].shape[0], \", C4:\", X_train[np.argwhere(y_train==4)].shape[0], \")\")\n",
        "print(\"class count val   : (C0:\", X_val[np.argwhere(y_val==0)].shape[0], \", C1:\", X_val[np.argwhere(y_val==1)].shape[0], \", C2:\", X_val[np.argwhere(y_val==2)].shape[0], \", C3:\", X_val[np.argwhere(y_val==3)].shape[0], \", C4:\", X_val[np.argwhere(y_val==4)].shape[0], \")\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IyYW_sZu7jO"
      },
      "source": [
        "## shuffle data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wzXgF0UuSTU"
      },
      "source": [
        "print(\"Before shuffle, y_val[:30] =\", y_val[:30])\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
        "X_val, y_val = shuffle(X_val, y_val, random_state=0)\n",
        "\n",
        "print(\"After  shuffle, y_val[:30] =\", y_val[:30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KsK6Rf1nbrc"
      },
      "source": [
        "## one-hot encoding y\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KQcEpFql30V"
      },
      "source": [
        "print(\"Before one-hot encoding y_train[0] =\", y_train[0])\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(\"After one-hot encoding y_train[0] =\", y_train[0])\n",
        "print(\"y_train shape =\", y_train.shape)\n",
        "print(\"y_val shape =\", y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCpaF182hXC1"
      },
      "source": [
        "# 2 Model\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "https://keras.io/layers/about-keras-layers/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uh5ap-eiDy6"
      },
      "source": [
        "#@title build paper model with Keras Functional-API\n",
        "n_obs, feature, depth = X_train.shape\n",
        "\n",
        "inp = Input(shape=(feature, depth))\n",
        "C = Conv1D(filters=32, kernel_size=5, strides=1)(inp)\n",
        "\n",
        "C11 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\n",
        "A11 = Activation(\"relu\")(C11)\n",
        "C12 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\n",
        "S11 = Add()([C12, C])\n",
        "A12 = Activation(\"relu\")(S11)\n",
        "M11 = MaxPooling1D(pool_size=5, strides=2)(A12)\n",
        "\n",
        "C21 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\n",
        "A21 = Activation(\"relu\")(C21)\n",
        "C22 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\n",
        "S21 = Add()([C22, M11])\n",
        "A22 = Activation(\"relu\")(S11)\n",
        "M21 = MaxPooling1D(pool_size=5, strides=2)(A22)\n",
        "\n",
        "C31 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\n",
        "A31 = Activation(\"relu\")(C31)\n",
        "C32 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\n",
        "S31 = Add()([C32, M21])\n",
        "A32 = Activation(\"relu\")(S31)\n",
        "M31 = MaxPooling1D(pool_size=5, strides=2)(A32)\n",
        "\n",
        "C41 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\n",
        "A41 = Activation(\"relu\")(C41)\n",
        "C42 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\n",
        "S41 = Add()([C42, M31])\n",
        "A42 = Activation(\"relu\")(S41)\n",
        "M41 = MaxPooling1D(pool_size=5, strides=2)(A42)\n",
        "\n",
        "C51 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\n",
        "A51 = Activation(\"relu\")(C51)\n",
        "C52 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\n",
        "S51 = Add()([C52, M41])\n",
        "A52 = Activation(\"relu\")(S51)\n",
        "M51 = MaxPooling1D(pool_size=5, strides=2)(A52)\n",
        "\n",
        "F1 = Flatten()(M51)\n",
        "\n",
        "D1 = Dense(32)(F1)\n",
        "A6 = Activation(\"relu\")(D1)\n",
        "D2 = Dense(32)(A6)\n",
        "D3 = Dense(5)(D2)\n",
        "A7 = Softmax()(D3)\n",
        "\n",
        "model = Model(inputs=inp, outputs=A7)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4d3DR6SwfsH"
      },
      "source": [
        "#@title plot model\n",
        "plot_model(model, to_file=\"model_plot.png\", show_shapes=True, dpi=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhmWyvN8iXWN"
      },
      "source": [
        "#@title Compile Model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unm-RGclifJE"
      },
      "source": [
        "# 3 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7c_6NYGinzM"
      },
      "source": [
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXEU1R-ek13v"
      },
      "source": [
        "# The history.history attribute is a dictionary\n",
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSQOYZm_zB8x"
      },
      "source": [
        "#@title Training history visualization\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6,12))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "ax1.plot(history.history['accuracy'])  # fix\n",
        "ax1.plot(history.history['val_accuracy'])  # fix\n",
        "ax1.set_title('Model accuracy')\n",
        "ax1.set(ylabel='Accuracy', xlabel='Epoch')\n",
        "ax1.legend(['Train', 'Valid'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "ax2.plot(history.history['loss'])\n",
        "ax2.plot(history.history['val_loss'])\n",
        "ax2.set_title('Model loss')\n",
        "ax2.set(ylabel='Loss', xlabel='Epoch')\n",
        "ax2.legend(['Train', 'Valid'], loc='upper right')\n",
        "\n",
        "plt.savefig('train_history.png', dpi=72)  # <-- save plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApgSuCkCivrQ"
      },
      "source": [
        "#@title save model\n",
        "model.save(\"ecg_arrhythmia.keras\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZYUqGOuRzIP"
      },
      "source": [
        "#@title evaluate model with valid_set\n",
        "loss, acc = model.evaluate(X_val,  y_val, verbose=2)\n",
        "print(\"Valid_set accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7AlqiZ2i6HL"
      },
      "source": [
        "# 4 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRYueMQ1MLEO"
      },
      "source": [
        "#@title Prepare test data\n",
        "CLASSES = ['C0', 'C1', 'C2', 'C3', 'C4']\n",
        "\n",
        "df2 = pd.read_csv(\"mitbih_test.csv\", header=None)\n",
        "M = df2.values  # numpy array M\n",
        "X_test = M[:, :-1]\n",
        "y_test = M[:, -1].astype(int)\n",
        "X_test = X_test[:,:,np.newaxis]  # as shape (number_of_data, X_lengh, channel)\n",
        "y_test = to_categorical(y_test)  # one-hot encoding\n",
        "\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbp4f2fnRPjG"
      },
      "source": [
        "#@title restore model\n",
        "model = load_model('ecg_arrhythmia.keras')\n",
        "model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mUpsp_ci3Hg"
      },
      "source": [
        "#@title start inference model\n",
        "y_pred = model.predict(X_test, batch_size=1000)\n",
        "print(\"y_pred shape =\", y_pred.shape)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozbFfc6k77mz",
        "cellView": "form"
      },
      "source": [
        "#@title plot ROC curve\n",
        "#@title Compute ROC curve and ROC area for each class\n",
        "N_CLASSES = len(CLASSES)\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(N_CLASSES):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "\n",
        "lw = 2\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(N_CLASSES)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(N_CLASSES):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= N_CLASSES\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
        "#                ''.format(roc_auc[\"micro\"]),\n",
        "#          color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "# plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "#          label='macro-average ROC curve (area = {0:0.2f})'\n",
        "#                ''.format(roc_auc[\"macro\"]),\n",
        "#          color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['cornflowerblue', 'green', 'darkorange', 'red'])\n",
        "for i, color in zip(range(N_CLASSES), colors):\n",
        "    ax.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve: {0}\\n(area = {1:0.2f})'\n",
        "             ''.format(CLASSES[i], roc_auc[i]))\n",
        "\n",
        "ax.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "ax.set(xlim=(0.0, 1.0), ylim=(0.0, 1.0))\n",
        "ax.axis('equal')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Some extension of Receiver operating characteristic to multi-class')\n",
        "ax.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4cEzyMA7GmC",
        "cellView": "form"
      },
      "source": [
        "#@title plot confusion matrix\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix\n",
        "class_names = CLASSES\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#         print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "#         print('Confusion matrix, without normalization')\n",
        "        pass\n",
        "\n",
        "#     print(cm)\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.set_title(title)\n",
        "#     plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    ax.axis('equal')\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        ax.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    ax.set_ylabel('True label')\n",
        "    ax.set_xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzKC-VKa3FwB"
      },
      "source": [
        "#@title classification report\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report\n",
        "\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1), target_names=CLASSES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey9YcoV_jETY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}