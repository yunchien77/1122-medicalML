{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y41z4vFgu4Mm"
      },
      "source": [
        "This notebook is modified from mtwenzel's work: Transfer learning Inception-V3.\n",
        "https://github.com/mtwenzel/parkinson-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ-adKBAi9yo"
      },
      "source": [
        "# Classifying PPMI DAT scans into Parkinson's Disease and Healthy Controls\n",
        "\n",
        "Licensed under [this](LICENSE) license.\n",
        "\n",
        "The data are a derivative of the DAT scans available from the [PPMI repository](https://www.ppmi-info.org/access-data-specimens/download-data/). They were processed to represent the central 5 slices of the putamen in one slice by averaging them. For details, please refer to the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK46L_mVmW_Q"
      },
      "source": [
        "#@title Download and unzip the data. {display-mode:'form'}\n",
        "#@markdown The data resides in the GitHub repository. For Hosted Runtime users, it is temporarily downloaded to the runtime's location.\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "zipurl = 'https://github.com/mtwenzel/parkinson-classification/raw/master/data/PPMI-classification.zip'\n",
        "zipresp = urlopen(zipurl)\n",
        "tempzip = open(\"PPMI-classification.zip\", \"wb\")\n",
        "tempzip.write(zipresp.read())\n",
        "tempzip.close()\n",
        "print(\"download complete, extracting...\")\n",
        "\n",
        "zf = ZipFile(\"PPMI-classification.zip\")\n",
        "zf.extractall(path = 'data/')\n",
        "zf.close()\n",
        "print(\"... done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w4QcbOqi9yx",
        "cellView": "code"
      },
      "source": [
        "#@title Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "# Visualize the Train/Val loss\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.signal import resample\n",
        "from scipy import interp\n",
        "from itertools import cycle, product"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vGhlufJXZNm"
      },
      "source": [
        "# 1 DataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlJrs0Mti9yz"
      },
      "source": [
        "#@title Set the data generators.\n",
        "#@markdown Data augmentation choices. Cell runs automatically if anything is changed.\n",
        "shear_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "zoom_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "width_shift_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "height_shift_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "rotation_range = 10 #@param {type:\"slider\", min:0, max:90, step:5}\n",
        "horizontal_flip = True #@param {type:\"boolean\"}\n",
        "vertical_flip = False #@param {type:\"boolean\"}\n",
        "#@markdown Data source (No need to change if the download succeeded.)\n",
        "data_directory = '/content/data/PPMI-classification/' #@param ['z:/Data/Parkinson_DATScans UKE/full_ppmi_data/png/', '/content/drive/My Drive/MEVIS/Data/PPMI-classification/'] {allow-input: true}\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=shear_range,\n",
        "    zoom_range=zoom_range,\n",
        "    width_shift_range=width_shift_range,\n",
        "    height_shift_range=height_shift_range,\n",
        "    rotation_range=rotation_range,\n",
        "    horizontal_flip=horizontal_flip,\n",
        "    vertical_flip=vertical_flip)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(os.path.join(data_directory, 'all_2d_train'), # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(109,91),\n",
        "                                                 color_mode='grayscale',\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='binary',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "# Data Generator for validation without data augmentation!\n",
        "val_datagen   = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow_from_directory(os.path.join(data_directory, 'all_2d_val'), # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(109,91),\n",
        "                                                 color_mode='grayscale',\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='binary',\n",
        "                                                 shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMf_qGgZwPwv"
      },
      "source": [
        "#@title Plot some training data from train_generator\n",
        "X_batch, y_batch = train_generator.next()\n",
        "print(\"X_batch shape:\", X_batch.shape, \"\\ty_batch shape:\", y_batch.shape)\n",
        "\n",
        "w=10\n",
        "h=10\n",
        "fig=plt.figure(figsize=(15, 6))\n",
        "columns = 10\n",
        "rows = 3\n",
        "for i in range(1, columns*rows +1):\n",
        "    img = X_batch[i]\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.title(y_batch[i])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img[:,:,0], cmap='bone')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y582IVFyXd2D"
      },
      "source": [
        "# 2 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9UeQBnwi9y2",
        "cellView": "code"
      },
      "source": [
        "#@title Build model with Functional API\n",
        "\n",
        "inputs = Input(shape=(109, 91, 1))\n",
        "x = Conv2D(64, kernel_size=(3,3), activation='relu')(inputs)\n",
        "x = MaxPool2D((2, 2), strides=2)(x)\n",
        "x = Conv2D(64, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool2D((2, 2), strides=2)(x)\n",
        "x = Conv2D(96, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool2D((2, 2), strides=2)(x)\n",
        "x = Conv2D(128, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool2D((2, 2), strides=2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# x = Dropout(rate=0.5)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4d3DR6SwfsH"
      },
      "source": [
        "#@title plot model\n",
        "plot_model(model, to_file=\"model_plot.png\", show_shapes=True, dpi=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZbTepTui9y4"
      },
      "source": [
        "## compile model\n",
        "Set up the trainable parameters.\n",
        "\n",
        "First train only the top layers (which were randomly initialized), i.e. freeze all convolutional InceptionV3 layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI9967K8i9y4"
      },
      "source": [
        "#@title Set up trainable parameters\n",
        "optimizer = 'adam' #@param ['adam', 'adagrad', 'adadelta', 'sgd'] {allow-input: true}\n",
        "\n",
        "if optimizer in ['adam', 'adagrad', 'adadelta', 'sgd']: # standard settings\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics = ['accuracy']) # categorical crossentropy would also do...\n",
        "else:\n",
        "    from tensorflow.keras.optimizers import SGD\n",
        "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9WhS5QIXiyc"
      },
      "source": [
        "# 3 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F08l0mwmi9y7",
        "cellView": "code"
      },
      "source": [
        "#@title Run training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30, # Originally, 500 epochs!\n",
        "    validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPuHoj1_i9y9",
        "cellView": "form"
      },
      "source": [
        "#@title Plot train and validation loss/accuracy\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6,12))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "ax1.plot(history.history['accuracy'])  # fix\n",
        "ax1.plot(history.history['val_accuracy'])  # fix\n",
        "ax1.set_title('Model accuracy')\n",
        "ax1.set(ylabel='Accuracy', xlabel='Epoch')\n",
        "ax1.legend(['Train', 'Valid'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "ax2.plot(history.history['loss'])\n",
        "ax2.plot(history.history['val_loss'])\n",
        "ax2.set_title('Model loss')\n",
        "ax2.set(ylabel='Loss', xlabel='Epoch')\n",
        "ax2.legend(['Train', 'Valid'], loc='upper right')\n",
        "\n",
        "plt.savefig('train_history.png', dpi=72)  # <-- save plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7AlqiZ2i6HL"
      },
      "source": [
        "# 4 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRYueMQ1MLEO"
      },
      "source": [
        "#@title Prepare test data\n",
        "CLASSES = list(val_generator.class_indices.keys())\n",
        "\n",
        "y_test = val_generator.labels\n",
        "y_test = y_test[:, np.newaxis]\n",
        "\n",
        "print(\"CLASSES:\", CLASSES)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mUpsp_ci3Hg",
        "cellView": "code"
      },
      "source": [
        "#@title start inference model\n",
        "y_pred = model.predict(val_generator,\n",
        "                       verbose=1)\n",
        "print(\"y_pred shape =\", y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb_ey1pC4GRS"
      },
      "source": [
        "# plot histogram of y_pred\n",
        "threshold = 0.5\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(y_pred, bins=30)  # arguments are passed to np.histogram\n",
        "plt.axvline(x=threshold, color='r', linestyle='--')\n",
        "plt.title(f\"threshold = {threshold:.2f}\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozbFfc6k77mz",
        "cellView": "form"
      },
      "source": [
        "#@title plot ROC curve\n",
        "#@title Compute ROC curve and ROC area for each class\n",
        "# N_CLASSES = len(CLASSES)\n",
        "N_CLASSES = 1\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(N_CLASSES):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "\n",
        "lw = 2\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(N_CLASSES)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(N_CLASSES):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= N_CLASSES\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
        "#                ''.format(roc_auc[\"micro\"]),\n",
        "#          color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "# plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "#          label='macro-average ROC curve (area = {0:0.2f})'\n",
        "#                ''.format(roc_auc[\"macro\"]),\n",
        "#          color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['cornflowerblue', 'green', 'darkorange', 'red'])\n",
        "for i, color in zip(range(N_CLASSES), colors):\n",
        "    ax.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve: {0}\\n(area = {1:0.2f})'\n",
        "             ''.format(CLASSES[i], roc_auc[i]))\n",
        "\n",
        "ax.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "ax.set(xlim=(0.0, 1.0), ylim=(0.0, 1.0))\n",
        "ax.axis('equal')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Some extension of Receiver operating characteristic to multi-class')\n",
        "ax.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4cEzyMA7GmC",
        "cellView": "form"
      },
      "source": [
        "#@title plot confusion matrix\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix\n",
        "class_names = CLASSES\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#         print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "#         print('Confusion matrix, without normalization')\n",
        "        pass\n",
        "\n",
        "#     print(cm)\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.set_title(title)\n",
        "#     plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    ax.axis('equal')\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        ax.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    ax.set_ylabel('True label')\n",
        "    ax.set_xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test[:,0], y_pred[:,0]>threshold)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzKC-VKa3FwB",
        "cellView": "form"
      },
      "source": [
        "#@title classification report\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report\n",
        "\n",
        "print(classification_report(y_test[:,0], y_pred[:,0]>threshold, target_names=CLASSES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey9YcoV_jETY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}